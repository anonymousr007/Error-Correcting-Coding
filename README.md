## Error-Correcting-Coding

### Part I Introduction and Foundations 

- 1. A Context for Error Correction Coding
  - 1.1 Purpose of This Book
  - 1.2 Introduction: Where Are Codes?
  - 1.3 The Communications System
  - 1.4 Basic Digital Communications
    - 1.4.1 Binary Phase-Shift Keying
    - 1.4.2 More General Digital Modulation
  - 1.5 Signal Detection
    - 1.5.1 The Gaussian Channel
    - 1 S.2 MAP and ML Detection
    - 1.5.3 Special Case: Binary Detection
    - 1.5.4 Probability of Error for Binary Detection
    - 1 S.5 Bounds on Performance: The Union Bound
    - 1.5.6 The Binary Symmetric Channel
    - 1 S.7 The BSC and the Gaussian Channel Model
  - 1.6 Memoryless Channels
  - 1.7 Simulation and Energy Considerations for Coded Signals
  - 1.8 Some Important Definitions
    - 1.8.1 Detection of Repetition Codes Over a BSC
    - 1.8.2 Soft-Decision Decoding of Repetition Codes Over the AWGN
    - 1.8.3 Simulation of Results
    - 1.8.4 Summary
  - 1.9 HammingCodes
    - 1.9.1 Hard-Input Decoding Hamming Codes
    - 1.9.2 Other Representations of the Hamming Code
      - An Algebraic Representation
      - A Polynomial Representation
      - A Trellis Representation
      - The Tanner Graph Representation
  - 1.10 The Basic Questions
  - 1.11 Historical Milestones of Coding Theory
  - 1.12 A Bit of Information Theory
    - 1.12.1 Definitions for Discrete Random Variables
      - Entropy and Conditional Entropy
      - Relative Entropy. Mutual Information. and Channel Capacity
    - 1.12.2 Definitions for Continuous Random Variables
    - 1.12.3 The Channel Coding Theorem
    - 1.12.4 “Proof“ of the Channel Coding Theorem
    - 1.12.5 Capacity for the Continuous-Time AWGN Channel
    - 1.12.6 Transmission at Capacity with Errors
    - 1.12.7 The Implication of the Channel Coding Theorem












